---
title: "Project 2"
author: 'Jake Goodman (Net ID: jakeg5) & Michael McClanahan (Net ID: mjm31)'
date: "11/2/2021"
output:
  html_document:
    toc: yes
    df_print: paged
  html_notebook:
    theme: readable
    toc: yes
    toc_float: yes
---


Generate the data

```{r}
library(lubridate)
library(tidyverse)

# read raw data and extract date column
train_raw = readr::read_csv(unz('train.csv.zip', 'train.csv'))
train_dates = train_raw$Date

# training data from 2010-02 to 2011-02
start_date = ymd("2010-02-01")
end_date = start_date %m+% months(13)

# split dataset into training / testing
train_ids = which(train_dates >= start_date & train_dates < end_date)
train = train_raw[train_ids, ]
test = train_raw[-train_ids, ]

# create the initial training data
readr::write_csv(train, 'train_ini.csv')

# create test.csv 
# removes weekly sales
test %>% 
  select(-Weekly_Sales) %>% 
  readr::write_csv('test.csv')

# create 10-fold time-series CV
num_folds = 10
test_dates = train_dates[-train_ids]

# month 1 --> 2011-03, and month 20 --> 2012-10.
# Fold 1 : month 1 & month 2, Fold 2 : month 3 & month 4 ...
for (i in 1:num_folds) {
    # filter fold for dates
    start_date = ymd("2011-03-01") %m+% months(2 * (i - 1))
    end_date = ymd("2011-05-01") %m+% months(2 * (i - 1))
    test_fold = test %>%
        filter(Date >= start_date & Date < end_date)
    
    # write fold to a file
    readr::write_csv(test_fold, paste0('fold_', i, '.csv'))
}
```



Prediction Function (data from most recent week)
```{r}
mypredict = function(t){
  
  start_date <- ymd("2011-03-01") %m+% months(2 * (t - 1))
  end_date <- ymd("2011-05-01") %m+% months(2 * (t - 1))
  test_current <- test %>%
    filter(Date >= start_date & Date < end_date) %>%
    select(-IsHoliday)
  
  train_pairs <- train[, 1:2] %>% count(Store, Dept) %>% filter(n != 0)
  test_pairs <- test_current[, 1:2] %>% count(Store, Dept) %>% filter(n != 0)
  unique_pairs <- intersect(train_pairs[, 1:2], test_pairs[, 1:2])
  
  # pick out the needed training samples, convert to dummy coding, then put them into a list
  train_split <- unique_pairs %>% 
    left_join(train, by = c('Store', 'Dept')) %>% 
    mutate(Wk = factor(ifelse(year(Date) == 2010, week(Date) - 1, week(Date)), levels = 1:52)) %>% 
    mutate(Yr = year(Date)) %>%
  train_split = as_tibble(model.matrix(~ Weekly_Sales + Store + Dept + Yr + Wk, train_split)) %>% group_split(Store, Dept)
  
  # do the same for the test set
  test_split <- unique_pairs %>% 
    left_join(test_current, by = c('Store', 'Dept')) %>% 
    mutate(Wk = factor(ifelse(year(Date) == 2010, week(Date) - 1, week(Date)), levels = 1:52)) %>% 
    mutate(Yr = year(Date))
  test_split = as_tibble(model.matrix(~ Store + Dept + Yr + Wk, test_split)) %>% mutate(Date = test_split$Date) %>% group_split(Store, Dept)

  # pre-allocate a list to store the predictions
  test_pred <- vector(mode = "list", length = nrow(unique_pairs))
  
  # perform regression for each split, note we used lm.fit instead of lm
  for (i in 1:nrow(unique_pairs)) {
    tmp_train <- train_split[[i]]
    tmp_test <- test_split[[i]]
    
    mycoef <- lm.fit(as.matrix(tmp_train[, -(2:4)]), tmp_train$Weekly_Sales)$coefficients
    mycoef[is.na(mycoef)] <- 0
    tmp_pred <- mycoef[1] + as.matrix(tmp_test[, 4:55]) %*% mycoef[-1]
    
    test_pred[[i]] <- cbind(tmp_test[, 2:3], Date = tmp_test$Date, Weekly_Pred = tmp_pred[,1])
  }
  
  # turn the list into a table at once, 
  # this is much more efficient then keep concatenating small tables
  test_pred <- bind_rows(test_pred) 
}
```


```{r}
train = readr::read_csv('train_ini.csv')
test = readr::read_csv('test.csv')

# save weighted mean absolute error WMAE
num_folds = 10
wae = rep(0, num_folds)

for (t in 1:num_folds) {
  # *** THIS IS YOUR PREDICTION FUNCTION ***
  test_pred = mypredict(t)
  # load fold file 
  fold_file = paste0('fold_', t, '.csv')
  new_train = readr::read_csv(fold_file, 
                               col_types = cols())

  train = train %>% add_row(new_train)
  # extract predictions matching up to the current fold
  scoring_tbl = new_train %>% 
      left_join(test_pred, by = c('Date', 'Store', 'Dept'))

  
  # compute WMAE
  actuals = scoring_tbl$Weekly_Sales

  preds = scoring_tbl$Weekly_Pred
  preds[is.na(preds)] = 0
  weights = if_else(scoring_tbl$IsHoliday, 5, 1)
  wae[t] = sum(weights * abs(actuals - preds)) / sum(weights)
}

print(wae)
print(mean(wae))
```


```{r}
  start_date <- ymd("2011-03-01") %m+% months(2 * (1 - 1))
  end_date <- ymd("2011-05-01") %m+% months(2 * (1 - 1))
  test_current <- test %>%
    filter(Date >= start_date & Date < end_date) %>%
    select(-IsHoliday)
  
  train_pairs <- train[, 1:2] %>% count(Store, Dept) %>% filter(n != 0)
  test_pairs <- test_current[, 1:2] %>% count(Store, Dept) %>% filter(n != 0)
  unique_pairs <- intersect(train_pairs[, 1:2], test_pairs[, 1:2])
  
  # pick out the needed training samples, convert to dummy coding, then put them into a list
  train_split <- unique_pairs %>% 
    left_join(train, by = c('Store', 'Dept')) %>% 
    mutate(Wk = factor(ifelse(year(Date) == 2010, week(Date) - 1, week(Date)), levels = 1:52)) %>% 
    mutate(Yr = year(Date))
  train_split = as_tibble(model.matrix(~ Weekly_Sales + Store + Dept + Yr + Wk, train_split)) %>% group_split(Store, Dept)
  train_tmp = train_split[[1]]
  matrix_tmp = as.matrix(train_tmp[, -(2:4)])
```

